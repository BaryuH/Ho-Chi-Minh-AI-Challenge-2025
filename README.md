# ðŸ§  PIKA Search - Interactive Video Retrieval System (HCMC-AIC 2025)

**PIKA Search** is an **AI-powered interactive video retrieval system** developed for **HCMC-AIC 2025**.

---

<p align="center">
  <img src="assets/logo.png" alt="PIKA Search Logo" width="800">
</p>

---

## ðŸŽ¥ Demo

> ðŸ”— [Live Demo Link](https://youtu.be/P8ddazL9jTU)

---

## ðŸ§  Team Roles

| Member | Role | Contribution |
|---------|------|---------------|
| [**Pham Nguyen Gia Huy**](https://github.com/BaryuH) | Team Lead, Backend & Model Integration | System architecture, pipeline, model deployment, data preprocessing, feature extraction, and indexing pipeline|
| [**Nguyen Gia Huy**](https://github.com/anhbilong) | Data Engineer | Data preprocessing, feature extraction, and indexing pipeline |
| [**Nguyen Quang Nghia**](https://github.com/JulianNguyen1610) | Data Engineer | Data preprocessing, feature extraction, and indexing pipeline |
| [**Tran Thi Hong Thanh**](https://github.com/ThankTran) | Frontend Developer (UI/UX & Optimazation) | Designed the entire user interface with focus on clean visuals, responsiveness, and smooth performance. Built the interactive result viewer for video playback and similarity visualization. |
| [**Pham Tuan Khang**](https://github.com/KhangPham205) | Frontend Developer (Integration & Optimazation & Perfomance) | Implemented API connections and custom hooks for backend integration. Managed data flow, caching, and optimization. Led code review and maintained project documentation. |


Frontend repository: ðŸ”—[Ho-Chi-Minh-AI-Challenge-2025_Front-end](https://github.com/KhangPham205/Ho-Chi-Minh-AI-Challenge-2025_Front-end)

---

## ðŸ“š Citations & Acknowledgements

We would like to express our gratitude to the following open-source projects and research teams whose work has made **PIKA Search** possible:

- ðŸ§  **[BEiT-3](https://github.com/microsoft/unilm/tree/master/beit3)** â€” for providing state-of-the-art vision-language pretraining models.
- ðŸ–¼ï¸ **[OpenAI CLIP ViT](https://github.com/openai/CLIP)** â€” for enabling robust visual-text embeddings and cross-modal search.
- ðŸ—ƒï¸ **[Milvus](https://milvus.io)** â€” for powering our large-scale vector similarity search engine.
- ðŸ” **[Elasticsearch](https://www.elastic.co/elasticsearch)** â€” for efficient text indexing and hybrid retrieval integration.

> Our team sincerely acknowledges these frameworks and their authors for advancing open research and enabling practical AI systems like **PIKA Search**.

---
